# KNN算法简介

## 1.KNN算法描述
kNN 可以用来进行分类或者回归，大致方法基本相同，本篇文章将主要介绍使用 kNN 进行分类。在样本量很大的情况下十分好用！

### 1.1找出K个与给定样本S距离最近的样本，即为K近邻
- k的取值，有时候会决定S的分类取向
- 所有的样本特征都需要计算出来，以用来计算跟样本最接近的K个邻居
- KD树可以加快这个计算速度
- 使用KNN算法，必不可少的是：归一化，即：防止单位为吨的坐标轴，被单位为毫米的坐标轴数据冲掉。
### 1.2归一化
    feat = F.normalize(inputs)#归一化特征


[KNN兔子演绎法](https://zhuanlan.zhihu.com/p/22345658)十分有用，可参照该文看算法具体过程。

## 2.KNN算法应用场景
### 2.1分类
- KNN可以从K近邻中，计算出样本S分别属于各个类别的概率

### 2.2回归
- 回归与分类的根本区别在于输出空间是否为一个度量空间。Loss函数的差异。

    - 回归的输出是一个度量空间，预测一个人5块的包子价格为6块，则误差为1，预测价格7块，则误差为2，因此有均方差loss。

    - 而分类问题中，预测错分类，那么就只有正确，错误选项，并没有误差问题。

## 3.gene论文中KNN的应用改进
- 最近邻的定义不再是前K个，而是跟最接近的那个对比，高于一定比例即可
- 按照camera进行了区分